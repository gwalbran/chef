#!/usr/bin/python

import getpass
import os
import subprocess

from celery import Celery

app = Celery('tasks')
app.config_from_object('<%= @celery_config.gsub(/.py$/, "") %>')

def watch_exec_wrapper(job_name, file_path, execute, execute_params):
    command = [
        "<%= node['imos_po']['watch_exec_wrapper'] %>",
        job_name,
        file_path,
        execute,
        execute_params
    ]
    print command
    subprocess.call(command)

<%
watchlists = Chef::Recipe::WatchJobs.get_watches(@watch_dir)
watchlists.each do |job_name, watchlist|
  watchlist['path'].each do |path|
    path = ::File.join(node['imos_po']['data_services']['incoming_dir'], path)
    execute = ::File.join(@data_services_dir, watchlist['execute'])
    execute_params = watchlist['execute_params']
%>
@app.task
def <%= job_name %>(file_path):
    watch_exec_wrapper("<%= job_name %>", file_path, "<%= execute %>", "<%= execute_params %>")

<%
  end
end %>

<%
s3cmd_parts = Chef::Recipe::WatchJobs.get_s3cmd(node).split(" ")
s3cmd_quoted = s3cmd_parts.map{ |s| "\"#{s}\""}.join(', ')
%>
@app.task(ignore_result=True)
def async_upload(src_path, dst_path):
    if not os.access(src_path, os.R_OK):
        raise Exception("ERROR uploading '{0}'. The file must exist and user '{1}' must have read access to it.".format(src_path, getpass.getuser()))
    command = [
        <%= s3cmd_quoted %>,
        "sync",
        "--no-preserve",
        src_path,
        os.path.join("<%= node['imos_po']['s3']['bucket'] %>", dst_path)
    ]
    print command
    ret = subprocess.call(command)
    if ret != 0:
        raise Exception("ERROR uploading '{0}' -> '{1}'".format(src_path, dst_path))

