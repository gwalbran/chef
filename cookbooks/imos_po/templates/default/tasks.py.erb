#!/usr/bin/python

from celery import Celery
import subprocess
from os import system, path

app = Celery('tasks')
app.config_from_object('<%= @celery_config.gsub(/.py$/, "") %>')

def watch_exec_wrapper(job_name, file_path, execute, execute_params):
    command = [
        "<%= node['imos_po']['watch_exec_wrapper'] %>",
        job_name,
        file_path,
        execute,
        execute_params
    ]
    print command
    subprocess.call(command)

<%
@watchlists.each do |job_name, watchlist|
  watchlist['path'].each do |path|
    path = ::File.join(node['imos_po']['data_services']['incoming_dir'], path)
    execute = ::File.join(@data_services_dir, watchlist['execute'])
    execute_params = watchlist['execute_params']
%>
@app.task(ignore_result=True)
def <%= job_name %>(file_path):
    watch_exec_wrapper("<%= job_name %>", file_path, "<%= execute %>", "<%= execute_params %>")

<%
  end
end %>

<%
s3cmd_parts = Chef::Recipe::WatchJobs.get_s3cmd(node).split(" ")
s3cmd_quoted = s3cmd_parts.map{ |s| "\"#{s}\""}.join(', ')
%>
@app.task(ignore_result=True)
def async_upload(src_path, dst_path):
    command = [
        <%= s3cmd_quoted %>,
        "sync",
        "--no-preserve",
        src_path,
        path.join("<%= node['imos_po']['s3']['bucket'] %>", dst_path)
    ]
    print command
    ret = subprocess.call(command)
    if ret != 0:
        raise Exception("ERROR uploading '%s' -> '%s'" % (src_path, dst_path))

